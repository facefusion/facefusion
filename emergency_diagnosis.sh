#!/bin/bash

echo "ğŸš¨ ç·Šæ€¥æ€§èƒ½è¨ºæ–­ï¼šãªãœ0.358ç§’ãªã®ã‹ï¼Ÿ"
echo "============================================"

echo ""
echo "1ï¸âƒ£ å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹BLASãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèª..."
pixi run -- python -c "
import numpy as np
print('=== BLAS Library Details ===')
print('NumPy version:', np.__version__)

# å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹BLASç¢ºèª
config = np.__config__
print('Build info:', config.show())

# ã‚ˆã‚Šè©³ç´°ãªBLASæƒ…å ±
try:
    from numpy.distutils.system_info import get_info
    blas_info = get_info('blas')
    print('BLAS info:', blas_info)
except:
    print('Cannot get detailed BLAS info')

# ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ã§ã®BLASç¢ºèª
try:
    import ctypes
    import ctypes.util
    accelerate_lib = ctypes.util.find_library('Accelerate')
    print('Accelerate framework path:', accelerate_lib)
except:
    print('Cannot check Accelerate framework')
"

echo ""
echo "2ï¸âƒ£ ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ç¢ºèª..."
pixi run -- python -c "
import numpy as np
import os

print('=== Threading Configuration ===')
print('CPU cores:', os.cpu_count())

# å„ç¨®ã‚¹ãƒ¬ãƒƒãƒ‰è¨­å®šç¢ºèª
env_vars = ['OMP_NUM_THREADS', 'OPENBLAS_NUM_THREADS', 'MKL_NUM_THREADS', 'VECLIB_MAXIMUM_THREADS']
for var in env_vars:
    print(f'{var}: {os.environ.get(var, \"Not set\")}')

# NumPyã®ã‚¹ãƒ¬ãƒƒãƒ‰æ•°ç¢ºèª
try:
    from threadpoolctl import threadpool_info
    print('Active threadpools:')
    for info in threadpool_info():
        print(f'  {info}')
except ImportError:
    print('threadpoolctl not available - installing...')
"

echo ""
echo "3ï¸âƒ£ è©³ç´°GEMMæ€§èƒ½ãƒ†ã‚¹ãƒˆï¼ˆè¤‡æ•°ã‚µã‚¤ã‚ºãƒ»ãƒ‡ãƒ¼ã‚¿å‹ï¼‰..."
pixi run -- python -c "
import numpy as np
import time

print('=== Detailed GEMM Performance Test ===')

# ãƒ†ã‚¹ãƒˆè¨­å®š
sizes = [1024, 2048, 4096]
dtypes = [np.float32, np.float64]

for dtype in dtypes:
    print(f'\\n--- Data type: {dtype.__name__} ---')
    for size in sizes:
        # ãƒ¡ãƒ¢ãƒªäº‹å‰å‰²ã‚Šå½“ã¦
        A = np.random.rand(size, size).astype(dtype)
        B = np.random.rand(size, size).astype(dtype)
        
        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        _ = np.dot(A, B)
        
        # å®Ÿæ¸¬å®šï¼ˆ3å›å¹³å‡ï¼‰
        times = []
        for _ in range(3):
            start = time.perf_counter()
            C = np.dot(A, B)
            end = time.perf_counter()
            times.append(end - start)
        
        avg_time = np.mean(times)
        gflops = (2 * size**3) / (avg_time * 1e9)
        print(f'Size {size}x{size}: {avg_time:.3f}s ({gflops:.1f} GFLOPS)')
"

echo ""
echo "4ï¸âƒ£ ãƒ¡ãƒ¢ãƒªãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ..."
pixi run -- python -c "
import numpy as np
import time

print('=== Memory Layout Optimization Test ===')

size = 4096
A = np.random.rand(size, size).astype(np.float32)

# C-contiguous (row major)
A_c = np.ascontiguousarray(A)
# Fortran-contiguous (column major) 
A_f = np.asfortranarray(A)

print('Array properties:')
print(f'C-contiguous: flags.c_contiguous={A_c.flags.c_contiguous}, flags.f_contiguous={A_c.flags.f_contiguous}')
print(f'F-contiguous: flags.c_contiguous={A_f.flags.c_contiguous}, flags.f_contiguous={A_f.flags.f_contiguous}')

# æ€§èƒ½æ¯”è¼ƒ
for name, arr in [('C-contiguous', A_c), ('F-contiguous', A_f)]:
    start = time.perf_counter()
    result = np.dot(arr, arr)
    elapsed = time.perf_counter() - start
    print(f'{name}: {elapsed:.3f}s')
"

echo ""
echo "5ï¸âƒ£ ç’°å¢ƒå¤‰æ•°ã®å•é¡Œç¢ºèª..."
pixi run -- python -c "
import os
print('=== Environment Variables Check ===')

# BLASé–¢é€£ç’°å¢ƒå¤‰æ•°
blas_vars = {
    'NPY_BLAS_ORDER': os.environ.get('NPY_BLAS_ORDER'),
    'OPENBLAS_NUM_THREADS': os.environ.get('OPENBLAS_NUM_THREADS'),
    'SCIPY_USE_ACCELERATE': os.environ.get('SCIPY_USE_ACCELERATE'),
    'NPY_LAPACK_ORDER': os.environ.get('NPY_LAPACK_ORDER')
}

for var, value in blas_vars.items():
    print(f'{var}: {value}')

# å•é¡Œã®å¯èƒ½æ€§
print('\\n=== Potential Issues ===')
if os.environ.get('OPENBLAS_NUM_THREADS') == '1':
    print('âš ï¸  OPENBLAS_NUM_THREADS=1 may limit performance')
if os.environ.get('NPY_BLAS_ORDER') != 'accelerate':
    print('âš ï¸  NPY_BLAS_ORDER is not set to accelerate')
"
